{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "!pip install gradio pandas textblob wordcloud matplotlib nltk scikit-learn sumy\n",
    "\n",
    "# Download necessary NLTK data\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "import string\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Predefined text inputs\n",
    "predefined_texts = {\n",
    "    \"Sample Text 1\": \"This is a sample text to demonstrate the text analysis capabilities of this tool. Feel free to modify this text and see the results.\",\n",
    "    \"Sample Text 2\": \"Another example text to showcase the functionality of the text analysis tool. Experiment with different texts to see how the analysis changes.\",\n",
    "    \"Sample Text 3\": \"Text analysis tools can provide insights into sentiment, keywords, and summaries. Try using different texts to explore these features.\"\n",
    "}\n",
    "\n",
    "# Text Summarization Function using Sumy\n",
    "def summarize_text(text, sentence_count=3):\n",
    "    parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
    "    summarizer = LsaSummarizer()\n",
    "    summary = summarizer(parser.document, sentence_count)\n",
    "    return \" \".join([str(sentence) for sentence in summary])\n",
    "\n",
    "# Preprocess Text Function\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Lowercase text\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\n",
    "    text = \" \".join([word for word in text.split() if word not in stopwords.words('english')])  # Remove stopwords\n",
    "    return text\n",
    "\n",
    "# Sentiment Analysis Function\n",
    "def sentiment_analysis(text):\n",
    "    blob = TextBlob(text)\n",
    "    return blob.sentiment.polarity\n",
    "\n",
    "# Generate Word Cloud Function\n",
    "def generate_wordcloud(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    wordcloud = WordCloud(stopwords=stop_words, background_color=\"white\", width=800, height=400).generate(text)\n",
    "    wordcloud_path = \"wordcloud.png\"\n",
    "    wordcloud.to_file(wordcloud_path)\n",
    "    return wordcloud_path\n",
    "\n",
    "# Extract Keywords Function\n",
    "def extract_keywords(text):\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    X = vectorizer.fit_transform([text])\n",
    "    indices = X[0].toarray().argsort()[0, -10:][::-1]\n",
    "    features = vectorizer.get_feature_names_out()\n",
    "    keywords = [features[i] for i in indices]\n",
    "    return keywords\n",
    "\n",
    "# Function to handle the analysis\n",
    "def analyze_text(selected_text, sentence_count):\n",
    "    try:\n",
    "        # Get the selected predefined text\n",
    "        text = predefined_texts[selected_text]\n",
    "\n",
    "        # Preprocess the text\n",
    "        processed_text = preprocess_text(text)\n",
    "\n",
    "        # Sentiment Analysis\n",
    "        sentiment = sentiment_analysis(processed_text)\n",
    "        sentiment_result = \"\"\n",
    "        if sentiment > 0:\n",
    "            sentiment_result = f\"Positive Sentiment ğŸ™‚ (Score: {sentiment:.2f})\"\n",
    "        elif sentiment < 0:\n",
    "            sentiment_result = f\"Negative Sentiment ğŸ˜Ÿ (Score: {sentiment:.2f})\"\n",
    "        else:\n",
    "            sentiment_result = f\"Neutral Sentiment ğŸ˜ (Score: {sentiment:.2f})\"\n",
    "\n",
    "        # Word Cloud\n",
    "        wordcloud_path = generate_wordcloud(processed_text)\n",
    "\n",
    "        # Keyword Extraction\n",
    "        keywords = extract_keywords(processed_text)\n",
    "        keywords_result = \", \".join(keywords)\n",
    "\n",
    "        # Text Summarization\n",
    "        summary = summarize_text(text, sentence_count=sentence_count)\n",
    "\n",
    "        return sentiment_result, wordcloud_path, keywords_result, summary\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred during analysis: {e}\", None, None, None\n",
    "\n",
    "# Gradio Interface\n",
    "iface = gr.Interface(\n",
    "    fn=analyze_text,\n",
    "    inputs=[\n",
    "        gr.components.Dropdown(\n",
    "            choices=list(predefined_texts.keys()),\n",
    "            label=\"Select Predefined Text\",\n",
    "            value=\"Sample Text 1\"\n",
    "        ),\n",
    "        gr.components.Slider(minimum=1, maximum=10, value=3, step=1, label=\"ğŸ”¢ Number of Summary Sentences\")\n",
    "    ],\n",
    "    outputs=[\n",
    "        gr.components.Textbox(label=\"ğŸ“Š Sentiment Analysis\"),\n",
    "        gr.components.Image(type=\"filepath\", label=\"ğŸŒ¥ï¸ Word Cloud\"),\n",
    "        gr.components.Textbox(label=\"ğŸ”‘ Top Keywords\"),\n",
    "        gr.components.Textbox(label=\"ğŸ“ Text Summary\")\n",
    "    ],\n",
    "    title=\"Linguistic Lens ğŸ”\",\n",
    "    description=\"A Text Analysis Tool ğŸ› ï¸\"\n",
    ")\n",
    "\n",
    "iface.launch(share=True)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
